{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gysOOQ2_6gz",
        "outputId": "28f7c740-7c1d-4b7b-cb1d-a70ac5a1e520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 14883    0 14883    0     0  20895      0 --:--:-- --:--:-- --:--:-- 20895\n",
            "Archive:  commit-f35fef1.zip\n",
            "f35fef14af3b4671239e59f648ba048e20072fc6\n",
            "   creating: 22-f35fef14af3b4671239e59f648ba048e20072fc6/\n",
            "  inflating: 22-f35fef14af3b4671239e59f648ba048e20072fc6/README.md  \n",
            "  inflating: 22-f35fef14af3b4671239e59f648ba048e20072fc6/hqq_utils.py  \n",
            "  inflating: 22-f35fef14af3b4671239e59f648ba048e20072fc6/inference_test.ipynb  \n",
            "  inflating: 22-f35fef14af3b4671239e59f648ba048e20072fc6/quant_cfg.py  \n",
            "  inflating: 22-f35fef14af3b4671239e59f648ba048e20072fc6/requirements.txt  \n",
            "  inflating: 22-f35fef14af3b4671239e59f648ba048e20072fc6/result.py  \n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/Silver-Wolf-han/22.git\n",
        "!curl -L -o commit-f35fef1.zip https://github.com/Silver-Wolf-han/22/archive/f35fef14af3b4671239e59f648ba048e20072fc6.zip\n",
        "!unzip commit-f35fef1.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd 22-f35fef14af3b4671239e59f648ba048e20072fc6\n",
        "!python3 -m venv venv\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCk9KbO0AEda",
        "outputId": "36c269b9-3c8f-4e2f-ece9-7310d3276c34"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/22-f35fef14af3b4671239e59f648ba048e20072fc6\n",
            "Error: Command '['/content/22-f35fef14af3b4671239e59f648ba048e20072fc6/venv/bin/python3', '-m', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.\n",
            "Collecting transformers==4.50.3 (from -r requirements.txt (line 2))\n",
            "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.6.0+cu124)\n",
            "Requirement already satisfied: timm==1.0.15 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.0.15)\n",
            "Collecting datasets==3.5.0 (from -r requirements.txt (line 7))\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting accelerate==1.6.0 (from -r requirements.txt (line 8))\n",
            "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting gemlite==0.4.4 (from -r requirements.txt (line 9))\n",
            "  Downloading gemlite-0.4.4.tar.gz (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hqq==0.2.5 (from -r requirements.txt (line 10))\n",
            "  Downloading hqq-0.2.5.tar.gz (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (3.2.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (0.15.2)\n",
            "Requirement already satisfied: huggingface-hub[cli] in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (0.31.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.3->-r requirements.txt (line 2)) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.3->-r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.3->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.3->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.3->-r requirements.txt (line 2)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.3->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.3->-r requirements.txt (line 2)) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.3->-r requirements.txt (line 2)) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.3->-r requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0->-r requirements.txt (line 7)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0->-r requirements.txt (line 7)) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0->-r requirements.txt (line 7)) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0->-r requirements.txt (line 7)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0->-r requirements.txt (line 7)) (0.70.15)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets==3.5.0->-r requirements.txt (line 7))\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0->-r requirements.txt (line 7)) (3.11.15)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.6.0->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from hqq==0.2.5->-r requirements.txt (line 10)) (0.8.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from hqq==0.2.5->-r requirements.txt (line 10)) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[cli]->-r requirements.txt (line 1)) (4.13.2)\n",
            "Collecting InquirerPy==0.3.4 (from huggingface-hub[cli]->-r requirements.txt (line 1))\n",
            "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface-hub[cli]->-r requirements.txt (line 1))\n",
            "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from InquirerPy==0.3.4->huggingface-hub[cli]->-r requirements.txt (line 1)) (3.0.51)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 4)) (11.2.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0->-r requirements.txt (line 7)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0->-r requirements.txt (line 7)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0->-r requirements.txt (line 7)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0->-r requirements.txt (line 7)) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0->-r requirements.txt (line 7)) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0->-r requirements.txt (line 7)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0->-r requirements.txt (line 7)) (1.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.3->-r requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.3->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.3->-r requirements.txt (line 2)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.3->-r requirements.txt (line 2)) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 3)) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0->-r requirements.txt (line 7)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0->-r requirements.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0->-r requirements.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface-hub[cli]->-r requirements.txt (line 1)) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.5.0->-r requirements.txt (line 7)) (1.17.0)\n",
            "Downloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m840.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
            "Building wheels for collected packages: gemlite, hqq\n",
            "  Building wheel for gemlite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gemlite: filename=gemlite-0.4.4-py3-none-any.whl size=66347 sha256=a194ae584547dbbad2ae0332dd450217a9d18e2cf1565914c00b9b4bd7300478\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/65/a0/468117bbfeb33df8390442ac8ee60fb95d9a8a809a30f4952a\n",
            "  Building wheel for hqq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hqq: filename=hqq-0.2.5-py3-none-any.whl size=73571 sha256=23368f65c8c58457b3c7865728c613edaf300a5038e77ec42e98fa505039283c\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/eb/db/16db55c3304e28a274af607616614945f124896912cd1236d3\n",
            "Successfully built gemlite hqq\n",
            "Installing collected packages: pfzy, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gemlite, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, InquirerPy, nvidia-cusolver-cu12, transformers, datasets, accelerate, hqq\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.52.2\n",
            "    Uninstalling transformers-4.52.2:\n",
            "      Successfully uninstalled transformers-4.52.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.7.0\n",
            "    Uninstalling accelerate-1.7.0:\n",
            "      Successfully uninstalled accelerate-1.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed InquirerPy-0.3.4 accelerate-1.6.0 datasets-3.5.0 fsspec-2024.12.0 gemlite-0.4.4 hqq-0.2.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pfzy-0.3.4 transformers-4.50.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXos36b4AgD5",
        "outputId": "9b0fb6e3-0f4d-44f9-cd11-f7228d1bcc22"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `aaslab` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `aaslab`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python result.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC7WWMZiuPxE",
        "outputId": "55de4136-d54e-4947-d6b7-69d45abb691e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rconfig.json:   0% 0.00/878 [00:00<?, ?B/s]\rconfig.json: 100% 878/878 [00:00<00:00, 6.99MB/s]\n",
            "2025-05-30 15:38:45.539011: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1748619525.813026    3733 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1748619525.886215    3733 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-30 15:38:46.464561: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model.safetensors.index.json: 100% 20.9k/20.9k [00:00<00:00, 87.7MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.97G [00:00<?, ?B/s]\u001b[AXet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 0.00/1.46G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/4.97G [00:00<01:12, 68.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 41.9M/4.97G [00:00<00:28, 173MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   1% 10.5M/1.46G [00:00<00:25, 56.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/4.97G [00:00<00:21, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 105M/4.97G [00:00<00:20, 242MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   2% 31.5M/1.46G [00:00<00:15, 92.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   4% 52.4M/1.46G [00:00<00:12, 111MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 136M/4.97G [00:00<00:25, 193MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   5% 73.4M/1.46G [00:00<00:11, 124MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 168M/4.97G [00:00<00:26, 180MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   6% 94.4M/1.46G [00:00<00:10, 135MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 189M/4.97G [00:01<00:28, 170MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   8% 115M/1.46G [00:00<00:09, 137MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 210M/4.97G [00:01<00:29, 162MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   9% 136M/1.46G [00:01<00:09, 137MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 241M/4.97G [00:01<00:27, 172MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  11% 168M/1.46G [00:01<00:07, 168MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 262M/4.97G [00:01<00:26, 176MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  14% 199M/1.46G [00:01<00:06, 190MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  15% 220M/1.46G [00:01<00:07, 172MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 294M/4.97G [00:01<00:27, 171MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  17% 241M/1.46G [00:01<00:07, 156MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 315M/4.97G [00:01<00:29, 157MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 336M/4.97G [00:01<00:28, 162MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  18% 262M/1.46G [00:01<00:07, 156MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  19% 283M/1.46G [00:01<00:07, 158MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 357M/4.97G [00:02<00:31, 147MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  21% 304M/1.46G [00:02<00:08, 143MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 377M/4.97G [00:02<00:32, 140MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  22% 325M/1.46G [00:02<00:08, 137MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 398M/4.97G [00:02<00:34, 131MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  24% 346M/1.46G [00:02<00:07, 146MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 419M/4.97G [00:04<02:42, 28.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  25% 367M/1.46G [00:04<00:38, 28.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 451M/4.97G [00:04<01:45, 42.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  27% 398M/1.46G [00:04<00:24, 43.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 482M/4.97G [00:04<01:13, 60.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  29% 419M/1.46G [00:04<00:19, 52.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 503M/4.97G [00:05<01:03, 70.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  30% 440M/1.46G [00:04<00:15, 64.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 524M/4.97G [00:05<00:52, 84.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  32% 461M/1.46G [00:05<00:12, 77.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 556M/4.97G [00:05<00:40, 110MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  33% 482M/1.46G [00:05<00:10, 94.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 577M/4.97G [00:05<00:35, 124MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  35% 514M/1.46G [00:05<00:07, 122MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 598M/4.97G [00:05<00:32, 135MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  37% 535M/1.46G [00:05<00:07, 122MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 629M/4.97G [00:05<00:28, 152MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  38% 556M/1.46G [00:05<00:06, 132MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 650M/4.97G [00:05<00:28, 151MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  40% 577M/1.46G [00:05<00:06, 138MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 671M/4.97G [00:05<00:30, 142MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  41% 598M/1.46G [00:05<00:06, 137MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 692M/4.97G [00:06<00:33, 128MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  42% 619M/1.46G [00:06<00:06, 139MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  44% 640M/1.46G [00:06<00:05, 142MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 713M/4.97G [00:06<00:34, 123MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 734M/4.97G [00:06<00:33, 128MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  45% 661M/1.46G [00:06<00:06, 131MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 755M/4.97G [00:06<00:31, 132MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  47% 682M/1.46G [00:08<00:28, 27.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 776M/4.97G [00:08<02:28, 28.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  48% 703M/1.46G [00:08<00:20, 36.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 797M/4.97G [00:08<01:50, 37.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  50% 724M/1.46G [00:08<00:15, 48.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 818M/4.97G [00:09<01:25, 48.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  51% 744M/1.46G [00:09<00:12, 59.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 839M/4.97G [00:09<01:11, 57.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  52% 765M/1.46G [00:09<00:09, 70.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 860M/4.97G [00:09<01:00, 68.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  55% 797M/1.46G [00:09<00:07, 93.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 881M/4.97G [00:09<00:50, 80.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  56% 818M/1.46G [00:09<00:06, 100MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 902M/4.97G [00:09<00:44, 91.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  57% 839M/1.46G [00:09<00:05, 107MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 923M/4.97G [00:09<00:37, 108MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  59% 860M/1.46G [00:09<00:05, 120MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 944M/4.97G [00:09<00:32, 124MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  60% 881M/1.46G [00:09<00:04, 131MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 965M/4.97G [00:10<00:29, 136MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  62% 912M/1.46G [00:10<00:03, 158MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 986M/4.97G [00:10<00:26, 152MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.01G/4.97G [00:10<00:25, 153MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  65% 944M/1.46G [00:10<00:03, 162MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.03G/4.97G [00:10<00:25, 152MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  66% 965M/1.46G [00:10<00:03, 162MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.05G/4.97G [00:10<00:24, 157MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  68% 986M/1.46G [00:10<00:03, 156MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.07G/4.97G [00:10<00:26, 148MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  69% 1.01G/1.46G [00:12<00:16, 27.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.09G/4.97G [00:13<02:26, 26.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  71% 1.04G/1.46G [00:13<00:10, 41.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.12G/4.97G [00:13<01:33, 41.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/4.97G [00:13<01:13, 51.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  73% 1.07G/1.46G [00:13<00:06, 57.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.16G/4.97G [00:13<00:59, 63.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  75% 1.09G/1.46G [00:13<00:05, 68.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  76% 1.11G/1.46G [00:13<00:04, 80.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.18G/4.97G [00:13<00:51, 73.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.21G/4.97G [00:13<00:42, 88.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  78% 1.14G/1.46G [00:13<00:03, 100MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.24G/4.97G [00:13<00:32, 114MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  80% 1.16G/1.46G [00:13<00:02, 111MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.26G/4.97G [00:14<00:29, 127MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  81% 1.18G/1.46G [00:13<00:02, 126MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  83% 1.21G/1.46G [00:13<00:01, 141MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.29G/4.97G [00:14<00:23, 156MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  84% 1.23G/1.46G [00:14<00:01, 138MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.31G/4.97G [00:14<00:28, 130MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  85% 1.25G/1.46G [00:14<00:01, 121MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.33G/4.97G [00:14<00:28, 128MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  87% 1.27G/1.46G [00:14<00:01, 120MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.35G/4.97G [00:14<00:29, 123MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  88% 1.29G/1.46G [00:14<00:01, 120MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.37G/4.97G [00:14<00:30, 119MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  90% 1.31G/1.46G [00:14<00:01, 112MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.39G/4.97G [00:15<00:31, 113MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  91% 1.33G/1.46G [00:16<00:03, 34.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.42G/4.97G [00:16<01:40, 35.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  93% 1.35G/1.46G [00:16<00:02, 44.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.44G/4.97G [00:16<01:17, 45.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  94% 1.37G/1.46G [00:18<00:04, 21.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.46G/4.97G [00:19<02:41, 21.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.49G/4.97G [00:19<01:42, 34.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  96% 1.41G/1.46G [00:18<00:01, 33.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.51G/4.97G [00:19<01:19, 43.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  98% 1.44G/1.46G [00:19<00:00, 47.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.53G/4.97G [00:19<01:03, 54.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors: 100% 1.46G/1.46G [00:19<00:00, 75.7MB/s]\n",
            "\n",
            "model-00001-of-00002.safetensors:  31% 1.55G/4.97G [00:19<00:50, 68.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.59G/4.97G [00:19<00:32, 105MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.63G/4.97G [00:19<00:25, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.67G/4.97G [00:19<00:18, 176MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.71G/4.97G [00:19<00:15, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.74G/4.97G [00:20<00:14, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.77G/4.97G [00:20<00:13, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.80G/4.97G [00:20<00:12, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.84G/4.97G [00:20<00:12, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.87G/4.97G [00:20<00:11, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.90G/4.97G [00:20<00:11, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.93G/4.97G [00:20<00:11, 268MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.96G/4.97G [00:20<00:11, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.99G/4.97G [00:22<00:43, 67.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.01G/4.97G [00:22<00:37, 78.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.04G/4.97G [00:22<00:28, 102MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.08G/4.97G [00:22<00:22, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.11G/4.97G [00:22<00:18, 157MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/4.97G [00:22<00:14, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.19G/4.97G [00:22<00:12, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.23G/4.97G [00:22<00:10, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/4.97G [00:23<00:09, 275MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.32G/4.97G [00:23<00:13, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.36G/4.97G [00:23<00:11, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.40G/4.97G [00:23<00:09, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.44G/4.97G [00:23<00:08, 281MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.49G/4.97G [00:23<00:08, 292MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.53G/4.97G [00:24<00:07, 306MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.57G/4.97G [00:24<00:07, 316MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.61G/4.97G [00:24<00:07, 322MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.65G/4.97G [00:24<00:07, 312MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.69G/4.97G [00:24<00:07, 286MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.73G/4.97G [00:24<00:07, 284MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.76G/4.97G [00:26<00:29, 74.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.79G/4.97G [00:26<00:23, 93.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.83G/4.97G [00:26<00:17, 125MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.87G/4.97G [00:26<00:13, 157MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.90G/4.97G [00:26<00:11, 175MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.95G/4.97G [00:26<00:09, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.98G/4.97G [00:29<00:49, 40.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.02G/4.97G [00:29<00:34, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.06G/4.97G [00:29<00:24, 79.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.10G/4.97G [00:29<00:17, 105MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.15G/4.97G [00:29<00:13, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.19G/4.97G [00:29<00:11, 159MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.23G/4.97G [00:29<00:09, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.27G/4.97G [00:30<00:07, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.31G/4.97G [00:30<00:06, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.36G/4.97G [00:30<00:06, 262MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.40G/4.97G [00:30<00:05, 279MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.44G/4.97G [00:30<00:05, 304MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.48G/4.97G [00:30<00:05, 275MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.52G/4.97G [00:30<00:04, 291MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.57G/4.97G [00:31<00:05, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.60G/4.97G [00:31<00:05, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.63G/4.97G [00:31<00:05, 264MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.66G/4.97G [00:31<00:04, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.69G/4.97G [00:31<00:04, 268MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.72G/4.97G [00:31<00:04, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.75G/4.97G [00:31<00:04, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.79G/4.97G [00:31<00:04, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.82G/4.97G [00:32<00:04, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.85G/4.97G [00:32<00:04, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.88G/4.97G [00:32<00:04, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.91G/4.97G [00:32<00:04, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.94G/4.97G [00:32<00:04, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/4.97G [00:32<00:04, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.01G/4.97G [00:32<00:03, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.05G/4.97G [00:33<00:03, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.08G/4.97G [00:33<00:03, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.11G/4.97G [00:33<00:03, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.14G/4.97G [00:33<00:04, 170MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.17G/4.97G [00:33<00:04, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.20G/4.97G [00:33<00:03, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.24G/4.97G [00:33<00:03, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.28G/4.97G [00:34<00:02, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.31G/4.97G [00:34<00:02, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.34G/4.97G [00:34<00:02, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.37G/4.97G [00:34<00:02, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.40G/4.97G [00:34<00:02, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.44G/4.97G [00:34<00:02, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.48G/4.97G [00:34<00:01, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.51G/4.97G [00:34<00:01, 281MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.54G/4.97G [00:35<00:01, 288MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.58G/4.97G [00:35<00:01, 302MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.62G/4.97G [00:35<00:01, 312MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.67G/4.97G [00:35<00:00, 314MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.70G/4.97G [00:35<00:00, 304MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.73G/4.97G [00:35<00:00, 279MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.76G/4.97G [00:35<00:00, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.79G/4.97G [00:35<00:00, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.82G/4.97G [00:36<00:00, 274MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.85G/4.97G [00:36<00:00, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.90G/4.97G [00:36<00:00, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.93G/4.97G [00:36<00:00, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.97G/4.97G [00:36<00:00, 136MB/s]\n",
            "Fetching 2 files: 100% 2/2 [00:36<00:00, 18.47s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:26<00:00, 13.30s/it]\n",
            "generation_config.json: 100% 189/189 [00:00<00:00, 1.26MB/s]\n",
            "tokenizer_config.json: 100% 54.5k/54.5k [00:00<00:00, 28.4MB/s]\n",
            "tokenizer.json: 100% 9.09M/9.09M [00:00<00:00, 17.8MB/s]\n",
            "special_tokens_map.json: 100% 296/296 [00:00<00:00, 2.89MB/s]\n",
            "[HeadPrune] Pruned 2 heads per layer; new num_attention_heads = 22\n",
            "[MLP Prune] Pruned 20% of hidden channels from each MLP layer\n",
            "100% 87/87 [00:00<00:00, 46758.64it/s]\n",
            "100% 197/197 [00:15<00:00, 13.03it/s]\n",
            "Warm Up...: 100% 5/5 [10:46<00:00, 129.21s/it]\n",
            "Test Inference: 100% 10/10 [00:41<00:00,  4.18s/it]\n",
            "Prompt: How to learn a new language?\n",
            "Response:  10 tips\n",
            "Learning a new language can be a challenging but rewarding experience. Here are 10 tips to help you get started:\n",
            "\n",
            "1.  **Set your goals**: Before you begin, define your goals and motivation for learning the language. Are you traveling, working, or studying abroad? Do you want to improve your career prospects or connect with your heritage? Setting clear goals will help you stay motivated and focused.\n",
            "2.  **Find a language learning program**: There are many language learning programs available, both online and offline. Some popular options include Duolingo, Babbel, and Rosetta Stone. Choose a program that fits your learning style and goals.\n",
            "3.  **Practice consistently**: Consistency is key when it comes to language learning. Set aside time each day to practice, even if it's just for a few minutes. You can use language learning apps, watch TV shows or movies in the target language, or practice speaking with a language exchange partner.\n",
            "4.  **Focus on grammar and vocabulary**: Understanding the grammar and vocabulary of the language is essential to effective communication. Start with the basics and gradually build up to more complex concepts.\n",
            "5.  **Immerse yourself in the language**: Listen to music, watch TV shows or movies, and read\n",
            "\n",
            "Time Record: [4.1637783203125, 4.13840185546875, 4.14658447265625, 4.18232470703125, 4.15936181640625, 4.159203125, 4.216158203125, 4.17154443359375, 4.17873583984375, 4.2419111328125]\n",
            "Throughput Record: [61.7227864284359, 62.101267343185555, 61.978720485433406, 61.44907868294783, 61.78832507099654, 61.790682560135835, 60.95596692968319, 61.60787787140905, 61.50185363466519, 60.58589912740633] toks/s\n",
            "\n",
            "Throughput: 61.64343404143173 toks/s\n",
            "README.md: 100% 10.5k/10.5k [00:00<00:00, 49.3MB/s]\n",
            "test-00000-of-00001.parquet: 100% 733k/733k [00:00<00:00, 24.1MB/s]\n",
            "train-00000-of-00001.parquet: 100% 6.36M/6.36M [00:00<00:00, 129MB/s]\n",
            "validation-00000-of-00001.parquet: 100% 657k/657k [00:00<00:00, 306MB/s]\n",
            "Generating test split: 100% 4358/4358 [00:00<00:00, 31291.88 examples/s]\n",
            "Generating train split: 100% 36718/36718 [00:00<00:00, 396712.20 examples/s]\n",
            "Generating validation split: 100% 3760/3760 [00:00<00:00, 365847.38 examples/s]\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (289077 > 131072). Running this sequence through the model will result in indexing errors\n",
            "Evaluating...:   0% 0/141 [00:00<?, ?it/s]W0530 15:52:21.415000 3733 torch/_inductor/utils.py:1137] [0/1] Not enough SMs to use max_autotune_gemm mode\n",
            "Evaluating...: 100% 141/141 [07:00<00:00,  2.98s/it]\n",
            "Perplexity (PPL): 11.356743812561035\n"
          ]
        }
      ]
    }
  ]
}